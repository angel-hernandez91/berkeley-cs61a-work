CS61a Lecture 35 Notes April 27, 2015

Unix
    Map Reduce Framework
        A systems framework developed to run big applicaitions
        Such as using it to build the google search index, translation

    Systems research enables application development by defining and implementing abstractions:
        Sub-branches:
            Operating systems: provide a stable, consistent interface to unreliable, inconsistent
            hardware
            Networks: provdie a robust data transfer interface to constantly evolving communications
            infrastructure
            Databases: provide a declarative interface to complex software that stores and
            retrives information efficiently. 
            Distributed systems: provide a unified interface to a cluster of multiple machines
    A unifying property of effective systems:
        Hide complexity behind abstractions, but remain flexible. 

The Unix Operating Sytem
    BSD Unix (Berkeley)
    Essential features of the Unix operating system (and variants):
        Portability: The same operating system on different hardware
        Multi-tasking: Many processes run concurrently on a machine
        Plain Text: Data is stored and shared in text format
        Modularity: Small tools are composed flexibly via pipes
    The standard streams in a Unix-like operating system are similar to Python iterators
        (i.e. std in, std err, std out)

Python Programms
    The built-in input function reads a line from standard input
    The built-in print function writes a line to standard output

    The sys.stdin and sys.stdout values provide access to the Unix standard streams and files
    A python file has an interface that supports interation, read, and write methods
    Using these 'files' 

    For a python file:
    #!/usr/bin/env python 3  (if we write this then we simply run ex.py in the terminal, instead of python3 ex.py)
    import sys

    for line in sys.stdin:
        sys.stdout.write(' '.join(line))

MapReduce
    Big Data Processing
        MapReduce is a framework for batch processing of big data
        Framework: A system used by programmers to build applications
        Batch processing: All the data is available at the outset, and results aren't used until
        processing completes
        Big Data: Used to describe data sets so large and comprehensive that they can reveal facts
        about a whole population



MapReduce Evaluation Model
    Map phase: Apply a mapper function to all inputs, emitting intermediate key-value pairs
        The mapper takes an interable value containing inputs, such as lines of text
        The mapper yields zero or more key-value pairs for each input

    Reduce phase: For each intermediate key, apply a reducer function to accumulate all values
    associated with that key

    That reducer takes an iterable value containing intermediate key-value pairs
    All pairs with the same key appear consecutively
    The reducer yields zero more values, each associated with that intermediate key

MapReduce Assumptions
    Contraints on the mapper and reducer:
        The mapper must be equivalent to applying a deterministic pure function
        to each input independently
        The reducer must be equivalent to applying a deterministic pure function
        to the sequence of values for each key

    Benefits of function programming:
        When a program contains only pure functions, call expressions can be evaluated
        in any order, lazily, and in parallel
        Referential transparaency: a call expression can be replaced by its value without
        changing





MapReduce Application
    Python example
    The mapper and reducer are both self-contained Python programs
    They reach from standard input and write to standard output

    Reducer takes in key, value pairs, and takes an iterator over the key, values pairs

